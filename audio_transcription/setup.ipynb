{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f082e7",
   "metadata": {},
   "source": [
    "## Make sure we have our dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1823fc",
   "metadata": {},
   "source": [
    "### Now, because we have a Dockerfile for our development environment... this should just work...\n",
    "To run your determined Jupyter notebook with this image...\n",
    "\n",
    "```yaml\n",
    "## replace this \n",
    "environment:\n",
    "  add_capabilities: null\n",
    "  drop_capabilities: null\n",
    "  environment_variables: {}\n",
    "  force_pull_image: false\n",
    "  image:\n",
    "    cpu: determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-9119094\n",
    "    cuda: determinedai/environments:cuda-11.3-pytorch-1.10-tf-2.8-gpu-9119094 ### this guy right here\n",
    "\n",
    "##replace it with this \n",
    "\n",
    "    cuda: katestephens/kate-nemo:<version>\n",
    "\n",
    "## you're welcome :)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3020d225",
   "metadata": {},
   "source": [
    "### If you don't want to use Jupyter in Determined and you just wanna use VSCode in a Determined shell... do the below\n",
    "create a `determined_config.yaml` in your homedir on your local machine with the following\n",
    "```yaml\n",
    "bind_mounts:\n",
    "  - container_path: /run/determined/workdir/shared_fs\n",
    "    host_path: /mnt/mapr_nfs/<path_to_det_share>/determined/det_share\n",
    "    propagation: rprivate\n",
    "    read_only: false\n",
    "  - container_path: /determined_shared_fs\n",
    "    host_path: /mnt/mapr_nfs/<path_to_det_checkpoints>/determined/det_checkpoints\n",
    "    propagation: rprivate\n",
    "    read_only: false\n",
    "  - container_path: /mnt/mapr_nfs\n",
    "    host_path: /mnt/mapr_nfs\n",
    "    propagation: rprivate\n",
    "    read_only: false\n",
    "debug: false\n",
    "description: my-awesome-nb\n",
    "entrypoint: null\n",
    "environment:\n",
    "  add_capabilities: null\n",
    "  drop_capabilities: null\n",
    "  environment_variables: {}\n",
    "  force_pull_image: false\n",
    "  image:\n",
    "    cpu: determinedai/environments:py-3.8-pytorch-1.10-tf-2.8-cpu-9119094\n",
    "    cuda: katestephens/kate-nemo:<version>\n",
    "  pod_spec: null\n",
    "  ports: null\n",
    "  slurm: null\n",
    "idle_timeout: null\n",
    "notebook_idle_type: kernels_or_terminals\n",
    "resources:\n",
    "  agent_label: ''\n",
    "  devices: null\n",
    "  resource_pool: kubernetes\n",
    "  slots: 1\n",
    "  weight: 1\n",
    "work_dir: null\n",
    "```\n",
    "Now... you'll want to make sure you have the mapping to det master in your local dev environment\n",
    "```bash\n",
    "echo $DET_MASTER\n",
    "```\n",
    "\n",
    "if nothing shows up...\n",
    "`export DET_MASTER=<ipaddrOfDet:port>`\n",
    "better yet... add it to your `~/.bashrc` and `source ~/.bashrc`\n",
    "\n",
    "To test that you're really talking to `DET_MASTER` run `det shell list` from your terminal\n",
    "\n",
    "To start a shell with the config/docker image loaded from YOUR terminal run\n",
    "```bash\n",
    "det shell start --show-ssh-command --config-file ~/determined_config.yaml\n",
    "```\n",
    "\n",
    "Then add the ssh host to your vscode instance (https://docs.determined.ai/latest/interfaces/ide-integration.html#visual-studio-code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330862b7",
   "metadata": {},
   "source": [
    "### Last Step... we wanna check our dependencies... especially apex..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc814d6-1d71-4049-aba1-7db25cfe0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did I return apex?! If not... oopsie no Apex found uncomment the lines in this block\n",
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 10703, done.\u001b[K\n",
      "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
      "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
      "remote: Total 10703 (delta 169), reused 168 (delta 100), pack-reused 10425\u001b[K\n",
      "Receiving objects: 100% (10703/10703), 15.21 MiB | 980.00 KiB/s, done.\n",
      "Resolving deltas: 100% (7360/7360), done.\n",
      "Using pip 22.3.1 from /Users/kthorpe/miniconda3/envs/nemo/lib/python3.9/site-packages/pip (python 3.9)\n",
      "\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option / --install-option. Consider using --config-settings for more flexibility.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /Users/kthorpe/src/UIforML/audio_transcription/apex\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l  Running command python setup.py egg_info\n",
      "\n",
      "  Warning: Torch did not find available GPUs on this system.\n",
      "   If your intention is to cross-compile, this is not an error.\n",
      "  By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "  Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "  and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "  If you wish to cross-compile for a single specific architecture,\n",
      "  export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.13.1\n",
      "\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"/Users/kthorpe/src/UIforML/audio_transcription/apex/setup.py\", line 137, in <module>\n",
      "      _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)\n",
      "    File \"/Users/kthorpe/src/UIforML/audio_transcription/apex/setup.py\", line 17, in get_cuda_bare_metal_version\n",
      "      raw_output = subprocess.check_output([cuda_dir + \"/bin/nvcc\", \"-V\"], universal_newlines=True)\n",
      "  TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/Users/kthorpe/miniconda3/envs/nemo/bin/python -c '\u001b[0m\n",
      "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
      "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "\u001b[34m  #\u001b[0m\n",
      "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
      "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
      "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
      "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
      "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
      "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
      "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
      "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  try:\u001b[0m\n",
      "\u001b[34m      import setuptools\u001b[0m\n",
      "\u001b[34m  except ImportError as error:\u001b[0m\n",
      "\u001b[34m      print(\u001b[0m\n",
      "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
      "\u001b[34m          \"the build environment.\",\u001b[0m\n",
      "\u001b[34m          file=sys.stderr,\u001b[0m\n",
      "\u001b[34m      )\u001b[0m\n",
      "\u001b[34m      sys.exit(1)\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  __file__ = %r\u001b[0m\n",
      "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
      "\u001b[34m      filename = __file__\u001b[0m\n",
      "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
      "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
      "\u001b[34m  else:\u001b[0m\n",
      "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
      "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/Users/kthorpe/src/UIforML/audio_transcription/apex/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' egg_info --egg-base /private/var/folders/f_/76vtbfxn2bl60jyn9rxfpvqc0000gp/T/pip-pip-egg-info-6l8piyy4\u001b[0m\n",
      "  \u001b[1;35mcwd\u001b[0m: /Users/kthorpe/src/UIforML/audio_transcription/apex/\n",
      "\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "#make sure we have all our dependencies\n",
    "import os\n",
    "from os.path import exists, join, basename, splitext\n",
    "\n",
    "if not exists('apex'):\n",
    " !pip list | grep apex\n",
    " !echo \"did I return apex?! If not... oopsie no Apex found uncomment the lines in this block\"\n",
    "\n",
    "!git clone https://github.com/NVIDIA/apex\n",
    "!cd ./apex && pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11445c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 06:25:35) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb5ebc39dc6fce5457fdab3d1e4a22479c37d64432fabe7b58333d39c0b67da4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
